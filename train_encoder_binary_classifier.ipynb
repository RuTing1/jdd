{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 堆栈式自编码器\n",
    "#### 1 优点\n",
    "1. 以分类为目的的微调，惯用做法是丢掉堆栈式自编码网络的解码层，直接将隐藏层的输出/输入到分类器即可\n",
    "2. 经过预训练在微调得到的模型效果远远好于纯粹用监督学习得到的结果\n",
    "\n",
    "#### 2 步骤\n",
    "- step1:训练分类器找到分类问题较优的网络结构\n",
    "- step2:以分类问题的网络结构训练堆栈式自编码器的底层\n",
    "- step3:由step2获取的底层自编码器微调各个目标领域的分类器\n",
    "\n",
    "#### 3 相关数据\n",
    "- yhj_fine_tune_data = pd.read_hdf('yhj_fine_tune_data.hdf',key='fine_tune')  \n",
    "- yhj_encoding_data = pd.read_hdf('yhj_encoding_data.hdf',key='encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #数据读取\n",
    "# reader = pd.read_csv('./yhj_index_20181112.csv',encoding='gbk',index_col= False,chunksize=100000)\n",
    "\n",
    "# #获取微调的目标数据（正负样本比例1:1），并存储\n",
    "# target_y =  [' inv_desire', ' current_fin', ' load_desire', ' fund_desire', ' bank_desire', ' risk_desire', ' card_desire']\n",
    "\n",
    "# def get_df(file):\n",
    "#     data_splits = pd.DataFrame()\n",
    "#     for chunk in  file:\n",
    "#         for y in target_y:\n",
    "# #             cols = [col for col in chunk.columns if col not in list(set(target_y)-set(y))]\n",
    "# #             chunk = chunk.loc[:,cols]\n",
    "#             label = chunk.loc[chunk[y]==1,:]\n",
    "#             y_num = len(label)\n",
    "#             unlabel = chunk.loc[chunk[y]==0,:].sample(n=y_num,axis=0,random_state=123)\n",
    "# #             print(len(label),len(unlabel))\n",
    "#             if (len(label)!=0):\n",
    "#                 a = pd.concat([label,unlabel],axis=0).sample(frac=1) #数据打散,取数时需要做数据的标准化\n",
    "#                 a['type'] = y\n",
    "#                 data_splits = data_splits.append(a)\n",
    "#             else:\n",
    "#                 continue\n",
    "#     return data_splits\n",
    "\n",
    "# data = get_df(reader)\n",
    "# data = data.drop(['dt'],axis=0)\n",
    "# data.to_hdf('yhj_fine_tune_data.hdf',key='fine_tune')\n",
    "\n",
    "# #堆栈式自编码器数据获取\n",
    "# data = pd.DataFrame()\n",
    "# i = 0\n",
    "# for chunk in reader:\n",
    "#     target_y =  [' inv_desire', ' current_fin', ' load_desire', ' fund_desire', ' bank_desire', ' risk_desire', ' card_desire']\n",
    "#     cols = [col for col in chunk.columns if col not in target_y]\n",
    "#     chunk = chunk.loc[:,cols]\n",
    "#     if (i <=20):\n",
    "#         data = data.append(chunk)\n",
    "#     else:\n",
    "#         pass\n",
    "#     i = i + 1\n",
    "    \n",
    "# # data.to_hdf('yhj_encoding_data.hdf',key='encoding') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2:自编码器网络设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhj_encoding_data = pd.read_hdf('yhj_encoding_data.hdf',key='encoding')\n",
    "yhj_encoding_data = yhj_encoding_data.drop([' dt'],axis=1)\n",
    "X_data = yhj_encoding_data.fillna(0)\n",
    "X_data = preprocessing.scale(X_data)\n",
    "X_train = X_data[:1500000]\n",
    "X_val = X_data[1500000:]\n",
    "# len(X_data) 2100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#堆栈式自编码器\n",
    "#模型参数\n",
    "model = 'relu'\n",
    "n_epoch = 200\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001\n",
    "print_freq = 10\n",
    "sess = tf.InteractiveSession()\n",
    "act = tf.nn.relu\n",
    "act_recon = tf.nn.softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "x = tf.placeholder(tf.float32, shape=[None, 72], name='x')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1], name='y_')\n",
    "\n",
    "network = tl.layers.InputLayer(x, name='input_layer')\n",
    "#降噪层\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='denoising1')\n",
    "# 第一个降噪自编码器：1st layer\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, n_units=50, act=act, name=model + '1')\n",
    "x_recon1 = network.outputs\n",
    "recon_layer1 = tl.layers.ReconLayer(network, x_recon=x, n_units=72, act=act_recon, name='recon_layer1')\n",
    "# 第二个降噪自编码器：2nd layer\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, n_units=30, act=act, name=model + '2')\n",
    "#因为第二个降噪自编码器的输入来自第一个降噪自编码器，因此其重构输出目标也是接近上一层输出\n",
    "recon_layer2 = tl.layers.ReconLayer(network, x_recon=x_recon1, n_units=50, act=act_recon, name='recon_layer2')\n",
    "# 分类器3rd layer\n",
    "# network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "network = tl.layers.DenseLayer(network,n_units=1, act=tf.identity, name='output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##逐层贪婪预训练 Greedy Layer-Wise Pretrain\n",
    "#初始化所有变量\n",
    "sess = tf.InteractiveSession()\n",
    "tl.layers.initialize_global_variables(sess)\n",
    "# Pre-train\n",
    "print(\"\\nAll Network Params before pre-train\")\n",
    "network.print_params()\n",
    "print(\"\\nPre-train Layer 1\")\n",
    "#预训练阶段只开启desonising1层，各降噪自编码器内部dropout层\n",
    "#pretrain用于快速实现自编码器深度神经网络的逐层贪婪预训练\n",
    "recon_layer1.pretrain(\n",
    "    sess, x=x, X_train=X_train, X_val=X_val, denoise_name='denoising1', n_epoch=100, batch_size=320, print_freq=10, save=False, save_name='w1pre_')\n",
    "print(\"\\nPre-train Layer 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_layer2.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name='denoising1', n_epoch=60, batch_size=320, print_freq=10, save=False)\n",
    "print(\"\\nAll Network Params after pre-train\")\n",
    "# network.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型为ckpt格式\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess,'./stack_encoder.ckpt')\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自编码器的网络结构，读取保存的模型\n",
    "act = tf.nn.relu\n",
    "x = tf.placeholder(tf.float32, shape=[None, 72], name='x')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1], name='y_')\n",
    "network = tl.layers.InputLayer(x, name='input_layer')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='denoising1')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, n_units=50, act=act, name= 'relu1')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, n_units=30, act=act, name= 'relu2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重载网络\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, save_path = './stack_encoder.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#微调\n",
    "# 定义损失函数和衡量指标\n",
    "# tl.cost.cross_entropy 在内部使用 tf.nn.sparse_softmax_cross_entropy_with_logits() 实现 softmax\n",
    "#cost = tl.cost.cross_entropy(y, y_, name = 'cost')\n",
    "\n",
    "#定义分类网络层\n",
    "\n",
    "#####构建NetworkStructure.loss\n",
    "network = tl.layers.DenseLayer(network,n_units=6, act=tf.identity, name='class_1')\n",
    "network = tl.layers.DenseLayer(network,n_units=1, act=tf.identity, name='output')\n",
    "y = network.outputs\n",
    "loss = tl.cost.mean_squared_error( y,y_)\n",
    "# loss = tl.cost.binary_cross_entropy(y,y_,name='entropy')\n",
    "#####构建NetworkStructure.acc\n",
    "# correct_prediction = tf.equal(tf.arg_max(y,1),y_)\n",
    "# acc = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "#auc = compute_auc(y,y_,500)\n",
    "\n",
    "# 定义 optimizer\n",
    "train_params = network.all_params\n",
    "train_op = tf.train.GradientDescentOptimizer(0.005).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读数\n",
    "yhj_fine_tune_data = pd.read_hdf('yhj_fine_tune_data.hdf',key='fine_tune')\n",
    "yhj_fine_tune_data = yhj_fine_tune_data.drop([' dt'],axis=1)\n",
    "yhj_fine_tune_data = yhj_fine_tune_data.fillna(0)\n",
    "# yhj_fine_tune_data = yhj_fine_tune_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data,y):\n",
    "    target_y =  [' inv_desire', ' current_fin', ' load_desire', ' fund_desire', ' bank_desire', ' risk_desire', ' card_desire']\n",
    "    cols = [col for col in data.columns if col not in set(target_y)-set([y])]\n",
    "    target_data = data.loc[data['type']==y,cols]\n",
    "    target_data = target_data.drop(['type'],axis=1)\n",
    "    target_data = target_data.fillna(0)\n",
    "    train = target_data[:round(len(target_data)*0.9)]\n",
    "    test = target_data[round(len(target_data)*0.9):]\n",
    "    new_cols = [col for col in target_data if col not in [y]]\n",
    "    x_train = train.loc[:,new_cols]\n",
    "    x_train = preprocessing.scale(x_train)\n",
    "    y_train = train[[y]]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "    x_test = test.loc[:,new_cols]\n",
    "    x_test = preprocessing.scale(x_test)\n",
    "    y_test = test[[y]]\n",
    "    y_train = y_train.values\n",
    "    y_val = y_val.values\n",
    "    y_test = y_test.values\n",
    "    return X_train, X_val, y_train, y_val,x_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, x_test, y_test = get_data( yhj_fine_tune_data,' inv_desire')\n",
    "print(len(X_train),len( X_val),len(x_test))\n",
    "#44487 4943 5492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fine-tune process\n",
    "n_epoch = 1000\n",
    "batch_size = 320\n",
    "learning_rate = 0.0001\n",
    "print_freq = 100\n",
    "\n",
    "# Initialize all variables including weights, biases and the variables in train_op\n",
    "tl.layers.initialize_global_variables(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    start_time = time.time()\n",
    "    for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
    "        feed_dict = {x: X_train_a, y_: y_train_a}\n",
    "        #微调阶段开启各降噪编码器内部Dropout层\n",
    "        feed_dict.update(network.all_drop)  # enable noise layers\n",
    "        #而denoising1只在预训练过程中开启，微调时则关闭\n",
    "        feed_dict[tl.layers.LayersConfig.set_keep['denoising1']] = 1  # disable denoising layer\n",
    "        sess.run(train_op, feed_dict=feed_dict)\n",
    "    #每个epoch完结后，在训练集和测试集上做测试\n",
    "    if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:\n",
    "        print(\"Epoch %d of %d took %fs\" % (epoch + 1, n_epoch, time.time() - start_time))\n",
    "        train_loss, train_acc, n_batch = 0, 0, 0\n",
    "        #在训练集上测试\n",
    "        for X_train_a, y_train_a in tl.iterate.minibatches(X_train, y_train, batch_size, shuffle=True):\n",
    "            #关闭所有dropout层\n",
    "            dp_dict = tl.utils.dict_to_one(network.all_drop)  # disable noise layers\n",
    "            feed_dict = {x: X_train_a, y_: y_train_a}\n",
    "            feed_dict.update(dp_dict)\n",
    "            err  = sess.run([loss], feed_dict=feed_dict)[0]\n",
    "            train_loss += err\n",
    "#             train_acc += ac\n",
    "            n_batch += 1\n",
    "        print(\"   train loss: %f\" % (train_loss / n_batch))\n",
    "#         print(\"   train acc: %f\" % (train_acc / n_batch))\n",
    "        train_loss_list.append(train_loss/ n_batch)\n",
    "        val_loss, val_acc, n_batch = 0, 0, 0\n",
    "        #在验证集上测试\n",
    "        for X_val_a, y_val_a in tl.iterate.minibatches(X_val, y_val, batch_size, shuffle=True):\n",
    "            #关闭所有dropout层\n",
    "            dp_dict = tl.utils.dict_to_one(network.all_drop)  # disable noise layers\n",
    "            feed_dict = {x: X_val_a, y_: y_val_a}\n",
    "            feed_dict.update(dp_dict)\n",
    "            err  = sess.run([loss], feed_dict=feed_dict)[0]\n",
    "            val_loss += err\n",
    "#             val_acc += ac\n",
    "            n_batch += 1\n",
    "        print(\"   val loss: %f\" % (val_loss / n_batch))\n",
    "#         print(\"   val acc: %f\" % (val_acc / n_batch))\n",
    "        val_loss_list.append(val_loss/ n_batch)\n",
    "print('Evaluation')\n",
    "test_loss, test_acc, n_batch = 0, 0, 0\n",
    "for X_test_a, y_test_a in tl.iterate.minibatches(x_test, y_test, batch_size, shuffle=True):\n",
    "    dp_dict = tl.utils.dict_to_one(network.all_drop)  # disable noise layers\n",
    "    feed_dict = {x: X_test_a, y_: y_test_a}\n",
    "    feed_dict.update(dp_dict)\n",
    "    err  = sess.run([loss], feed_dict=feed_dict)[0]\n",
    "    test_loss += err\n",
    "#     test_acc += ac\n",
    "    n_batch += 1\n",
    "print(\"   test loss: %f\" % (test_loss / n_batch))\n",
    "# print(\"   test acc: %f\" % (test_acc / n_batch))\n",
    "# print(\"   test acc: %f\" % np.mean(y_test == sess.run(y_op, feed_dict=feed_dict)))\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "# ref: https://www.tensorflow.org/versions/r0.8/how_tos/variables/index.html\n",
    "y_pred = tl.utils.predict(sess, network, x_test, x, y)\n",
    "saver = tf.train.Saver()\n",
    "# you may want to save the model\n",
    "save_path = saver.save(sess, \"./stack_encoder_bank_desire.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "# sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练测试阶段数据绘图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(round(n_epoch/print_freq +1))\n",
    "x = [i*10 for i in x]\n",
    "# print(train_loss_list,val_loss_list)\n",
    "assert len(x) == len(train_loss_list) and len(x)== len(val_loss_list), 'not in the same length'\n",
    "plt.plot(x, train_loss_list, 'r', label = 'train')\n",
    "plt.plot(x, train_loss_list, 'ro')\n",
    "plt.plot(x, val_loss_list, 'b', label = 'validate')\n",
    "plt.plot(x, val_loss_list, 'bo')\n",
    "plt.title('change of accuracy during training and validation')\n",
    "plt.xlabel('number of epoch')\n",
    "plt.ylabel('accuracy of classification')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def predictive_Accu(df, dep, score):\n",
    "    \n",
    "    fpr_dev = dict()\n",
    "    tpr_dev = dict()\n",
    "    roc_auc_dev = dict() \n",
    "    fpr_dev, tpr_dev, _ = roc_curve(df[dep], df[score])\n",
    "    roc_auc_dev = auc(fpr_dev, tpr_dev)\n",
    "\n",
    "    dev_roc = {\"fpr_dev\":fpr_dev,\"tpr_dev\":tpr_dev}\n",
    "    Dev_Roc = pd.DataFrame(dev_roc, columns=[\"fpr_dev\", \"tpr_dev\"])\n",
    " \n",
    "    return Dev_Roc, roc_auc_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型test数据AUC\n",
    "\n",
    "dev_pred = pd.DataFrame()\n",
    "\n",
    "dev_pred['score'] = y_pred.ravel().tolist()\n",
    "dev_pred['dep'] = y_test\n",
    "\n",
    "dev_roc, dev_auc = predictive_Accu(dev_pred, \"dep\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(dev_roc['fpr_dev'], dev_roc['tpr_dev'], color='darkorange', lw=lw,  label='ROC curve(Dev)(area = %0.3f)' % dev_auc)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
