{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用接口\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from TransferLearningWrapV1 import TransferLearningMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局变量\n",
    "IDcol = 'jdpin'\n",
    "label ='card_desire'\n",
    "file_dir = './'\n",
    "pipeline_model = 'data_precessed_pipeline_{}.pkl'.format('Mscale')  #数据预处理pipeline\n",
    "encoder_model = file_dir + 'model2/stack_encoder_lab_{}.ckpt'.format('Mscale') #堆栈式编码器模型\n",
    "encoder_cols = ['jdmall_user_f0002','jrlab_up_career_value']\n",
    "new_features = False\n",
    "model_type = 'MediumParity'\n",
    "# new_num = \n",
    "transfer_learning_model = file_dir+ 'model2/transfer_learning_lab_{}.ckpt'.format(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(data_name):\n",
    "    from preprocessing import DataProcessing\n",
    "    dp = DataProcessing(['pin']) \n",
    "    data = pd.read_csv('./data/{}.csv'.format(data_name))\n",
    "    y = data.loc[:,data_name]\n",
    "    cols=['jrlab_up_career_value']\n",
    "    data_X = data.loc[:,cols]\n",
    "    data_X.replace(['a','Z'],-1,inplace=True)\n",
    "    values = {'jrlab_up_pay_f0036': '2000-01-01', 'jrlab_up_pay_f0037':'2000-01-01', 'jdmall_ordr_f0001':'2000-01-01', 'jdmall_ordr_f0002':'2000-01-01'}\n",
    "    data_X.fillna(value=values,inplace=True)\n",
    "    # 时间类变量\n",
    "    time_vars = ['jrlab_up_pay_f0036','jrlab_up_pay_f0037','jdmall_ordr_f0001']\n",
    "    #异常时间数据处理\n",
    "    for var in time_vars:\n",
    "        data_X.loc[:,var] = data_X.loc[:,var].str[:10]\n",
    "    # data_time = data.loc[:,time_vars]\n",
    "    time_vars = ['jrlab_up_pay_f0036','jrlab_up_pay_f0037','jdmall_ordr_f0001']\n",
    "    data_X = dp.deal_with_time_variables(data_X,time_vars, end_date='2018-11-17')\n",
    "    data_X = data_X.fillna(-1)\n",
    "    data_precessed_pipeline = joblib.load('data_precessed_pipeline_Mscale .pkl')\n",
    "    data_X_scale = data_precessed_pipeline.transform(data_X)\n",
    "    data_scale = pd.DataFrame(data_X_scale)\n",
    "    data_scale.columns = cols\n",
    "    data_scale[data_name] = y.values\n",
    "    return data_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> RUN TIME: <deal_with_time_variables> : 0.015638351440429688\n"
     ]
    }
   ],
   "source": [
    "data = get_test_data(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test_col1'] = 1\n",
    "data['test_col2'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化迁移学习方法库\n",
    "tlm = TransferLearningMethod(data, None, 'card_desire', encoder_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] InputLayer  input_layer: (?, 396)\n",
      "[TL] DropoutLayer denoising1: keep: 0.800000 is_fix: False\n",
      "[TL] DropoutLayer drop1: keep: 0.800000 is_fix: False\n",
      "[TL] DenseLayer  relu1: 200 relu\n",
      "[TL] DropoutLayer drop2: keep: 0.500000 is_fix: False\n",
      "[TL] DenseLayer  relu2: 100 relu\n",
      "[TL] DropoutLayer drop3: keep: 0.500000 is_fix: False\n",
      "[TL] DenseLayer  relu3: 50 relu\n",
      "INFO:tensorflow:Restoring parameters from ./model2/stack_encoder_lab_Mscale.ckpt\n"
     ]
    }
   ],
   "source": [
    "#加载模型\n",
    "act = tf.nn.relu\n",
    "x = tf.placeholder(tf.float32, shape=[None, 396], name='x')\n",
    "network = tl.layers.InputLayer(x, name='input_layer')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='denoising1')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
    "network = tl.layers.DenseLayer(network, n_units=200, act=act, name= 'relu1')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
    "network = tl.layers.DenseLayer(network, n_units=100, act=act, name= 'relu2')\n",
    "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')\n",
    "network = tl.layers.DenseLayer(network, n_units=50, act=act, name='relu3')\n",
    "#重载网络\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, save_path = encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:,encoder_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] DenseLayer  output: 1 No Activation\n",
      "[TL]   [*] geting layers with output\n",
      "[TL]   got   0: output/bias_add:0   (?, 1)\n"
     ]
    }
   ],
   "source": [
    "layer_out = tlm.get_layer_outputs(network, sess, x, layer_name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "匹配数据量： 2949\n",
      "所传数据包含2个编码器外新特征...\n",
      "--> 迁移学习类型：异构型迁移学习\n",
      "[TL] DenseLayer  output: 1 No Activation\n",
      "Epoch 1 of 100 took 0.168949s\n",
      "   train loss: 1.294516\n",
      "   val loss: 1.695792\n",
      "Epoch 10 of 100 took 0.079895s\n",
      "   train loss: 0.598021\n",
      "   val loss: 0.597826\n",
      "Epoch 20 of 100 took 0.080642s\n",
      "   train loss: 0.555636\n",
      "   val loss: 0.517679\n",
      "Epoch 30 of 100 took 0.079394s\n",
      "   train loss: 0.496538\n",
      "   val loss: 0.484515\n",
      "Epoch 40 of 100 took 0.079707s\n",
      "   train loss: 0.394006\n",
      "   val loss: 0.409839\n",
      "Epoch 50 of 100 took 0.078919s\n",
      "   train loss: 0.373364\n",
      "   val loss: 0.383667\n",
      "Epoch 60 of 100 took 0.082660s\n",
      "   train loss: 0.364104\n",
      "   val loss: 0.386202\n",
      "Epoch 70 of 100 took 0.079977s\n",
      "   train loss: 0.344017\n",
      "   val loss: 0.352157\n",
      "Epoch 80 of 100 took 0.081363s\n",
      "   train loss: 0.403222\n",
      "   val loss: 0.431726\n",
      "Epoch 90 of 100 took 0.080626s\n",
      "   train loss: 0.376754\n",
      "   val loss: 0.405016\n",
      "Epoch 100 of 100 took 0.079565s\n",
      "   train loss: 0.368725\n",
      "   val loss: 0.394677\n",
      "Evaluation\n",
      "   test loss: 0.380962\n",
      "Model saved in file: ./model2/transfer_learning_lab_card_desire.ckpt\n"
     ]
    }
   ],
   "source": [
    "dev_pred = tlm.retrain_classifier_nets(network, sess, x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
